{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the latest approved model as a real time endpoing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This notebook works best with the `Data Science 3.0` kernel on an `ml.t3.medium` instance type***.\n",
    "\n",
    "Run the [2_realtime_inference](./2_realtime_inference.ipynb) notebook prior to running the notebook. This notebook extracts the latest approved model from the model registry and deploys it as a realtime endpoint. It does so by running the following steps:\n",
    "\n",
    "1. Extract the latest approved model from the SageMaker model registry.\n",
    "\n",
    "1. Runs inferences for testing the real time deployed endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Install the necessary boto3 and sagemaker libraries to initialize session\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import tarfile\n",
    "import tempfile\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "from utils import load_config, print_pipeline_execution_summary\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set the logger to track all of the logs as this pipeline runs\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Config.yml file that contains information that is used across this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:10:48,340] p4111 {2294058105.py:2} INFO - {\n",
      "  \"aws\": {\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"sagemaker_execution_role\": \"arn:aws:iam::218208277580:role/service-role/AmazonSageMaker-ExecutionRole-20230911T184036\",\n",
      "    \"s3_bucket\": \"sagemaker-{region}-{account_id}\",\n",
      "    \"s3_prefix\": \"mlops-pipeline-model\"\n",
      "  },\n",
      "  \"presto\": {\n",
      "    \"host\": \"3.93.186.209\",\n",
      "    \"parameter\": \"8080\",\n",
      "    \"presto_credentials\": \"presto-credentials\"\n",
      "  },\n",
      "  \"pipeline\": {\n",
      "    \"training_pipeline_name\": \"mlops-pipeline-presto\",\n",
      "    \"transform_pipeline_name\": \"mlops-batch-inference\",\n",
      "    \"execution_display_name\": \"mlops-prestodb-pipeline\",\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"training_step\": {\n",
      "    \"training_target\": \"high_value_order\",\n",
      "    \"training_features\": [\n",
      "      \"total_extended_price\",\n",
      "      \"avg_discount\",\n",
      "      \"total_quantity\"\n",
      "    ],\n",
      "    \"sklearn_framework_version\": \"0.23-1\",\n",
      "    \"n_estimators\": 75,\n",
      "    \"max_depth\": 10,\n",
      "    \"min_samples_split\": 2,\n",
      "    \"max_features\": \"sqrt\",\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"base_job_name\": \"rf-sklearn\",\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"tuning_step\": {\n",
      "    \"step_name\": \"Train-And-Tune-Model\",\n",
      "    \"maximum_parallel_training_jobs\": 1,\n",
      "    \"maximum_training_jobs\": 2,\n",
      "    \"hyperparam_ranges\": {\n",
      "      \"n_estimators\": [\n",
      "        10,\n",
      "        150\n",
      "      ],\n",
      "      \"max_depth\": [\n",
      "        3,\n",
      "        20\n",
      "      ],\n",
      "      \"min_samples_split\": [\n",
      "        2,\n",
      "        10\n",
      "      ],\n",
      "      \"max_features\": [\n",
      "        \"sqrt\",\n",
      "        \"log2\"\n",
      "      ]\n",
      "    },\n",
      "    \"metric_definitions\": [\n",
      "      {\n",
      "        \"Name\": \"validation:auc\",\n",
      "        \"Regex\": \"auc (\\\\S+)\"\n",
      "      }\n",
      "    ],\n",
      "    \"objective_metric_name\": \"validation:auc\"\n",
      "  },\n",
      "  \"evaluation_step\": {\n",
      "    \"step_name\": \"Evaluate-Model\",\n",
      "    \"accuracy_condition_threshold\": 0.7,\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"evaluation_filename\": \"evaluation.json\"\n",
      "  },\n",
      "  \"transform_step\": {\n",
      "    \"step_name\": \"mlops-RandomForestTransform\",\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"num_hours_to_go_back\": 1,\n",
      "    \"output_prefix\": \"batch_transform_output\",\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"data_processing_step\": {\n",
      "    \"step_name\": \"Preprocess-Data\",\n",
      "    \"processing_instance_type\": \"ml.c5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"register_model_step\": {\n",
      "    \"step_name\": \"Register-Model\",\n",
      "    \"model_group\": \"mlops-presto\",\n",
      "    \"model_name\": \"mlops-presto\",\n",
      "    \"approval_status\": \"PendingManualApproval\",\n",
      "    \"inference_instance_types\": [\n",
      "      \"ml.t2.medium\",\n",
      "      \"ml.m5.xlarge\",\n",
      "      \"ml.m5.large\"\n",
      "    ],\n",
      "    \"transform_instance_types\": [\n",
      "      \"ml.m5.xlarge\"\n",
      "    ],\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"fail_step\": {\n",
      "    \"step_name\": \"AccuracyThresholdFailed\"\n",
      "  },\n",
      "  \"condition_step\": {\n",
      "    \"step_name\": \"Accuracy-Condition\"\n",
      "  },\n",
      "  \"realtime_endpoint\": {\n",
      "    \"endpoint_config_name\": \"random-forest-classifier\",\n",
      "    \"endpoint_name\": \"mlops-realtime-ep\",\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"min_instance_count\": 1,\n",
      "    \"max_instance_count\": 3\n",
      "  },\n",
      "  \"scripts\": {\n",
      "    \"preprocess_data\": \"code/presto_preprocess_for_training.py\",\n",
      "    \"evaluation\": \"code/evaluate.py\",\n",
      "    \"batch_transform_get_data\": \"code/presto_preprocess_for_batch_inference.py\",\n",
      "    \"batch_inference\": \"code/inference.py\",\n",
      "    \"training_script\": \"code/training.py\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config = load_config('config.yml')\n",
    "logger.info(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:14:48,422] p4111 {3955098175.py:18} INFO - bucket=sagemaker-us-east-1-218208277580, prefix=mlops-pipeline-model, role=arn:aws:iam::218208277580:role/service-role/AmazonSageMaker-ExecutionRole-20230911T184036\n"
     ]
    }
   ],
   "source": [
    "## initialize the sagemaker session, region, role bucket and pipeline session\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "## initialize the sagemaker client\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "\n",
    "## initialize the sagemaker run time client\n",
    "smr = boto3.client('sagemaker-runtime')\n",
    "\n",
    "## set the execution role and buckets for artifact storage\n",
    "role = config['aws']['sagemaker_execution_role']\n",
    "ci = boto3.client('sts').get_caller_identity()\n",
    "bucket = config['aws']['s3_bucket'].format(account_id=ci['Account'], region=region)\n",
    "prefix = config['aws']['s3_prefix']  # Prefix to S3 artifacts\n",
    "\n",
    "logger.info(f\"bucket={bucket}, prefix={prefix}, role={role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive created at /tmp/inference.py.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:10:52,604] p4111 {3409183890.py:20} INFO - Compressed inference script uploaded to: s3://sagemaker-us-east-1-218208277580/mlops-pipeline-model/inference/mlops/inference.py.tar.gz\n"
     ]
    }
   ],
   "source": [
    "## represents the source path of the inference file\n",
    "inference_dir_path = config['scripts']['batch_inference'] \n",
    "tmp_dir = tempfile.gettempdir()\n",
    "# Define the name of the output .tar.gz file\n",
    "output_filename = f\"{os.path.basename(inference_dir_path)}.tar.gz\"\n",
    "output_filepath = os.path.join(tmp_dir, output_filename)  # Temporary path to store the archive\n",
    "\n",
    "# Compress the directory or file\n",
    "with tarfile.open(output_filepath, \"w:gz\") as tar:\n",
    "    tar.add(inference_dir_path, arcname=os.path.basename(inference_dir_path))\n",
    "\n",
    "print(f\"Archive created at {output_filepath}\")\n",
    "\n",
    "## upload the compressed inference file into s3 to have it be used during inference and deploy the model\n",
    "compressed_inference_script_uri = session.upload_data(\n",
    "    path=output_filepath, \n",
    "    key_prefix=prefix + \"/inference/mlops\"  \n",
    ")\n",
    "\n",
    "logger.info(f\"Compressed inference script uploaded to: {compressed_inference_script_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, step is to get the latest approved model from the registry and deploy it as a real time endpoint\n",
    "---\n",
    "Finally, approve the model to launch the model deployment process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:10:56,494] p4111 {398380380.py:9} INFO - image_uri=683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "# Fetch container to use for training\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=config['aws']['region'],\n",
    "    version=config['training_step']['sklearn_framework_version'],\n",
    "    py_version=\"py3\",\n",
    "    instance_type=config['realtime_endpoint']['instance_type'],\n",
    ")\n",
    "logger.info(f\"image_uri={image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:11:03,638] p4111 {1078079786.py:23} INFO - Latest approved model package ARN: arn:aws:sagemaker:us-east-1:218208277580:model-package/mlops-presto/2\n"
     ]
    }
   ],
   "source": [
    "# Initialize the latest approved model package ARN to None\n",
    "latest_approved_model_package_arn = None\n",
    "\n",
    "# List all model packages and select the first one with 'Approved' status\n",
    "for p in sm.get_paginator('list_model_packages').paginate(\n",
    "        ModelPackageGroupName=config['register_model_step']['model_group'],\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "    ):\n",
    "    for package in p[\"ModelPackageSummaryList\"]:\n",
    "        \n",
    "        if package['ModelApprovalStatus'] == 'Approved':\n",
    "            latest_approved_model_package_arn = package[\"ModelPackageArn\"]\n",
    "            break  \n",
    "            \n",
    "    if latest_approved_model_package_arn:\n",
    "        break  \n",
    "\n",
    "if latest_approved_model_package_arn is None:\n",
    "    raise Exception(f\"No approved model package is found for {config['general']['model_group']} model package group\")\n",
    "\n",
    "# Print the latest approved model package ARN\n",
    "logger.info(f\"Latest approved model package ARN: {latest_approved_model_package_arn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the latest approved model package data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:11:48,206] p4111 {37962726.py:6} INFO - the model data url for the given approved model is -> s3://sagemaker-us-east-1-218208277580/978rkuzjppke-Train-An-5dmtvt3bN0-001-e5caefe5/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "latest_approved_model_package = sm.describe_model_package(ModelPackageName=latest_approved_model_package_arn)\n",
    "\n",
    "## getting the model data for the latest, approved model\n",
    "model_data_url = latest_approved_model_package['InferenceSpecification']['Containers'][0]['ModelDataUrl']\n",
    "\n",
    "logger.info(f\"the model data url for the given approved model is -> {model_data_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name : mlops-presto2024-02-24-00-11-53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:11:54,512] p4111 {2622133837.py:20} INFO - Model arn : arn:aws:sagemaker:us-east-1:218208277580:model/mlops-presto2024-02-24-00-11-53\n",
      "[2024-02-24 00:11:54,513] p4111 {2622133837.py:21} INFO - Model data url : s3://sagemaker-us-east-1-218208277580/978rkuzjppke-Train-An-5dmtvt3bN0-001-e5caefe5/output/model.tar.gz\n",
      "[2024-02-24 00:11:54,514] p4111 {2622133837.py:22} INFO - Model image uri : 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "dttm_suffix = datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_name = config['register_model_step']['model_name'] + dttm_suffix\n",
    "print(\"Model name : {}\".format(model_name))\n",
    "container_list = [{\n",
    "    'Image': image_uri,\n",
    "    'ModelDataUrl': model_data_url,\n",
    "    'Environment': {\n",
    "        'SAGEMAKER_PROGRAM': 'inference.py',  \n",
    "        'SAGEMAKER_SUBMIT_DIRECTORY': compressed_inference_script_uri, \n",
    "    }\n",
    "}]\n",
    "\n",
    "## create the model object and call deploy on it\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers=container_list\n",
    ")\n",
    "\n",
    "logger.info(\"Model arn : {}\".format(create_model_response[\"ModelArn\"]))\n",
    "logger.info(\"Model data url : {}\".format(model_data_url))\n",
    "logger.info(\"Model image uri : {}\".format(image_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the endpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random-forest-classifier2024-02-24-00-11-53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:11:59,902] p4111 {230702839.py:24} INFO - arn:aws:sagemaker:us-east-1:218208277580:endpoint-config/random-forest-classifier2024-02-24-00-11-53\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = config['realtime_endpoint']['endpoint_config_name'] + dttm_suffix\n",
    "instance_type = config['realtime_endpoint']['instance_type']\n",
    "min_instances = config['realtime_endpoint']['min_instance_count']\n",
    "max_instances = config['realtime_endpoint']['max_instance_count']\n",
    "\n",
    "print(endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': instance_type,\n",
    "        ## have max instance count configured here\n",
    "        'InitialInstanceCount': min_instances,\n",
    "        'InitialVariantWeight': 1,\n",
    "        'ModelName': model_name,\n",
    "        'VariantName': 'AllTraffic', \n",
    "        ## change your managed instance configuration here\n",
    "        \"ManagedInstanceScaling\":{\n",
    "            \"MaxInstanceCount\": max_instances,\n",
    "            \"MinInstanceCount\": min_instances,\n",
    "            \"Status\": \"ENABLED\",}\n",
    "         }])\n",
    "    \n",
    "logger.info(create_endpoint_config_response[\"EndpointConfigArn\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the cell below if you want to update your endpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Represents the new configuration added below (add your new model package arn below)\n",
    "\n",
    "# response = sm.update_endpoint(\n",
    "#     EndpointName=endpoint_name,\n",
    "#     EndpointConfigName=endpoint_config_name\n",
    "# )\n",
    "\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now finally, deploying this as a real time endpoint\n",
    "---\n",
    "\n",
    "Now, we finally deploy the latest approved model as a real time endpoint, for running inference on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:12:04,241] p4111 {3669751331.py:2} INFO - EndpointName=mlops-realtime-ep2024-02-24-00-11-53\n",
      "[2024-02-24 00:12:04,602] p4111 {3669751331.py:7} INFO - arn:aws:sagemaker:us-east-1:218208277580:endpoint/mlops-realtime-ep2024-02-24-00-11-53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-24 00:14:35,458] p4111 {3669751331.py:17} INFO - {'EndpointName': 'mlops-realtime-ep2024-02-24-00-11-53', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:218208277580:endpoint/mlops-realtime-ep2024-02-24-00-11-53', 'EndpointConfigName': 'random-forest-classifier2024-02-24-00-11-53', 'ProductionVariants': [{'VariantName': 'AllTraffic', 'DeployedImages': [{'SpecifiedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3', 'ResolvedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:e7fea5cd095518578d5cba832758d90d59cba68b7858464aabd2bffd83d96d03', 'ResolutionTime': datetime.datetime(2024, 2, 24, 0, 12, 5, 270000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1, 'ManagedInstanceScaling': {'Status': 'ENABLED', 'MinInstanceCount': 1, 'MaxInstanceCount': 3}}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2024, 2, 24, 0, 12, 4, 562000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 2, 24, 0, 14, 19, 96000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '820a335a-82ad-4cc1-abcb-1281b014461f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '820a335a-82ad-4cc1-abcb-1281b014461f', 'content-type': 'application/x-amz-json-1.1', 'content-length': '866', 'date': 'Sat, 24 Feb 2024 00:14:19 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = config['realtime_endpoint']['endpoint_name'] + dttm_suffix\n",
    "logger.info(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "logger.info(f\"Going to deploy the real time endpoint -> {create_endpoint_response['EndpointArn']}\")\n",
    "\n",
    "# wait for endpoint to reach a terminal state (InService) using describe endpoint\n",
    "describe_endpoint_response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "\n",
    "logger.info(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"total_extended_price\": 1.0, \"avg_discount\": 2, \"total_quantity\": 3, \"prediction\": 0}, {\"total_extended_price\": 66.77, \"avg_discount\": 12, \"total_quantity\": 2, \"prediction\": 0}]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run this cell to test the model inference with the newly deployed real time endpoint\n",
    "\n",
    "## create this from the config param.\n",
    "body_str = \"total_extended_price,avg_discount,total_quantity\\n1,2,3\\n66.77,12,2\"\n",
    "\n",
    "response = smr.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=body_str.encode('utf-8') ,\n",
    "    ContentType='text/csv',\n",
    ")\n",
    "\n",
    "response_str = response[\"Body\"].read().decode()\n",
    "response_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Transform on Amazon SageMaker Pipelines Integrated with PrestoDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This notebook works best with the `Data Science 3.0` kernel on an `ml.t3.medium` instance type***.\n",
    "\n",
    "Run the [0_model_training_pipeline](./0_model_training_pipeline.ipynb) notebook prior to running the notebook. This notebook runs a batch transform using the model trained in the previous notebook. It does so by running the following steps:\n",
    "\n",
    "1. Extract the latest approved model from the SageMaker model registry.\n",
    "\n",
    "1. Read raw data for inference from PrestoDB and stores in an Amazon S3 bucket.\n",
    "\n",
    "1. Create a SageMaker pipeline with a data processing step and a batch transform step to provide inference on the data. The inference results are also stored in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\aroraai\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "## Install the necessary boto3 and sagemaker libraries to initialize session\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "import logging\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "from typing import Dict, List\n",
    "from datetime import datetime, timedelta\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from utils import load_config, make_s3_prefix, print_pipeline_execution_summary\n",
    "\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.processing import  ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set the logger to track all of the logs as this pipeline runs\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Config.yml file that contains information that is used across this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 19:54:15,951] p17664 {2294058105.py:2} INFO - {\n",
      "  \"aws\": {\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"sagemaker_execution_role\": \"arn:aws:iam::015469603702:role/SageMakerRepoRole\",\n",
      "    \"s3_bucket\": \"sagemaker-{region}-{account_id}\",\n",
      "    \"s3_prefix\": \"mlops-pipeline-model\"\n",
      "  },\n",
      "  \"presto\": {\n",
      "    \"host\": \"3.93.186.209\",\n",
      "    \"parameter\": \"8080\",\n",
      "    \"user\": \"ec2-user\"\n",
      "  },\n",
      "  \"pipeline\": {\n",
      "    \"training_pipeline_name\": \"mlops-pipeline-presto\",\n",
      "    \"transform_pipeline_name\": \"mlops-batch-inference\",\n",
      "    \"execution_display_name\": \"mlops-prestodb-pipeline\",\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"training_step\": {\n",
      "    \"training_target\": \"high_value_order\",\n",
      "    \"training_features\": [\n",
      "      \"total_extended_price\",\n",
      "      \"avg_discount\",\n",
      "      \"total_quantity\"\n",
      "    ],\n",
      "    \"sklearn_framework_version\": \"0.23-1\",\n",
      "    \"n_estimators\": 75,\n",
      "    \"max_depth\": 10,\n",
      "    \"min_samples_split\": 2,\n",
      "    \"max_features\": \"sqrt\",\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"base_job_name\": \"rf-sklearn\",\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"tuning_step\": {\n",
      "    \"step_name\": \"Train-And-Tune-Model\",\n",
      "    \"maximum_parallel_training_jobs\": 1,\n",
      "    \"maximum_training_jobs\": 2,\n",
      "    \"hyperparam_ranges\": {\n",
      "      \"n_estimators\": [\n",
      "        10,\n",
      "        150\n",
      "      ],\n",
      "      \"max_depth\": [\n",
      "        3,\n",
      "        20\n",
      "      ],\n",
      "      \"min_samples_split\": [\n",
      "        2,\n",
      "        10\n",
      "      ],\n",
      "      \"max_features\": [\n",
      "        \"sqrt\",\n",
      "        \"log2\"\n",
      "      ]\n",
      "    },\n",
      "    \"metric_definitions\": [\n",
      "      {\n",
      "        \"Name\": \"validation:auc\",\n",
      "        \"Regex\": \"auc (\\\\S+)\"\n",
      "      }\n",
      "    ],\n",
      "    \"objective_metric_name\": \"validation:auc\"\n",
      "  },\n",
      "  \"evaluation_step\": {\n",
      "    \"step_name\": \"Evaluate-Model\",\n",
      "    \"accuracy_condition_threshold\": 0.7,\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"evaluation_filename\": \"evaluation.json\"\n",
      "  },\n",
      "  \"transform_step\": {\n",
      "    \"step_name\": \"mlops-RandomForestTransform\",\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"num_hours_to_go_back\": 1,\n",
      "    \"output_prefix\": \"batch_transform_output\",\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"data_processing_step\": {\n",
      "    \"step_name\": \"Preprocess-Data\",\n",
      "    \"processing_instance_type\": \"ml.c5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"register_model_step\": {\n",
      "    \"step_name\": \"Register-Model\",\n",
      "    \"model_group\": \"mlops-presto\",\n",
      "    \"model_name\": \"mlops-presto\",\n",
      "    \"approval_status\": \"PendingManualApproval\",\n",
      "    \"inference_instance_types\": [\n",
      "      \"ml.t2.medium\",\n",
      "      \"ml.m5.xlarge\",\n",
      "      \"ml.m5.large\"\n",
      "    ],\n",
      "    \"transform_instance_types\": [\n",
      "      \"ml.m5.xlarge\"\n",
      "    ],\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"fail_step\": {\n",
      "    \"step_name\": \"AccuracyThresholdFailed\"\n",
      "  },\n",
      "  \"condition_step\": {\n",
      "    \"step_name\": \"Accuracy-Condition\"\n",
      "  },\n",
      "  \"realtime_endpoint\": {\n",
      "    \"endpoint_config_name\": \"random-forest-classifier\",\n",
      "    \"endpoint_name\": \"mlops-realtime-ep\"\n",
      "  },\n",
      "  \"scripts\": {\n",
      "    \"preprocess_data\": \"code/presto_preprocess_for_training.py\",\n",
      "    \"evaluation\": \"code/evaluate.py\",\n",
      "    \"batch_transform_get_data\": \"code/presto_preprocess_for_batch_inference.py\",\n",
      "    \"batch_inference\": \"code/inference.py\",\n",
      "    \"training_script\": \"code/training.py\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config = load_config('config.yml')\n",
    "logger.info(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 19:54:16,051] p17664 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-02-23 19:54:17,295] p17664 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-02-23 19:54:18,825] p17664 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-02-23 19:54:21,567] p17664 {564713264.py:14} INFO - bucket=sagemaker-us-east-1-015469603702, prefix=mlops-pipeline-model, batch_transform_inference_prefix=batch_transform_inference/yyyy=2024/mm=2/dd=23/hh=14/mm=24,             batch_transform_data_prefix=batch_transform_data/yyyy=2024/mm=2/dd=23/hh=14/mm=24, role=arn:aws:iam::015469603702:role/SageMakerRepoRole\n"
     ]
    }
   ],
   "source": [
    "## initialize the sagemaker session, region, role bucket and pipeline session\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "role = config['aws']['sagemaker_execution_role']\n",
    "ci = boto3.client('sts').get_caller_identity()\n",
    "bucket = config['aws']['s3_bucket'].format(account_id=ci['Account'], region=region)\n",
    "prefix = config['aws']['s3_prefix']  # Prefix to S3 artifacts\n",
    "\n",
    "logger.info(f\"bucket={bucket}, prefix={prefix}, role={role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 19:54:21,626] p17664 {1309184461.py:3} INFO - the training features being used for this pipeline --> [\"total_extended_price\", \"avg_discount\", \"total_quantity\"]\n"
     ]
    }
   ],
   "source": [
    "# Convert your list to a JSON string\n",
    "training_features_str = json.dumps(config['training_step']['training_features'])\n",
    "logger.info(f\"the training features being used for this pipeline --> {training_features_str}\")\n",
    "\n",
    "# Define new pipeline parameters\n",
    "host_parameter = ParameterString(name=\"HostParameter\", default_value=config['presto']['host'])\n",
    "port_parameter = ParameterString(name=\"PortParameter\", default_value=config['presto']['parameter'])\n",
    "user_parameter = ParameterString(name=\"UserParameter\", default_value=config['presto']['user'])\n",
    "target_parameter = ParameterString(name=\"Target\", default_value=config['training_step']['training_target'])\n",
    "feature_parameter = ParameterString(name=\"Feature\", default_value=training_features_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameters'></a>\n",
    "\n",
    "### Pipeline input parameters\n",
    "\n",
    "Pipeline Parameters are input parameter when triggering a pipeline execution. They need to be explicitly defined when creating the pipeline and contain default values.\n",
    "\n",
    "Create parameters for the inputs to the pipeline. In this case, parameters will be used for:\n",
    "\n",
    "- `ProcessingInstanceType` - What EC2 instance type to use for processing.\n",
    "- `TrainingInstanceType` - What EC2 instance type to use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 19:54:22,248] p17664 {utilities.py:422} WARNING - The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "[2024-02-23 19:54:22,253] p17664 {image_uris.py:581} INFO - Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# What instance type to use for processing.\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=config['data_processing_step']['processing_instance_type']\n",
    ")\n",
    "\n",
    "## initializing the sklearn processor\n",
    "sklearn_processor = SKLearnProcessor(framework_version=config['training_step']['sklearn_framework_version'],\n",
    "                                     role=role,\n",
    "                                     instance_type=processing_instance_type,\n",
    "                                     instance_count=config['data_processing_step']['instance_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Image URI object to use while creating the model from the approved model in the registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 19:54:22,590] p17664 {2531010310.py:9} INFO - processing step image_uri=683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "# Fetch container to use for training\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=config['aws']['region'],\n",
    "    version=config['training_step']['sklearn_framework_version'],\n",
    "    py_version=\"py3\",\n",
    "    instance_type=config['data_processing_step']['processing_instance_type'],\n",
    ")\n",
    "logger.info(f\"processing step image_uri={image_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, step is to approve the model\n",
    "---\n",
    "Finally, approve the model to launch the model deployment process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 19:54:24,879] p17664 {1612686606.py:18} INFO - for model_group=mlops-presto, latest_model_package_arn=arn:aws:sagemaker:us-east-1:015469603702:model-package/mlops-presto/3\n"
     ]
    }
   ],
   "source": [
    "sm = boto3.client(\"sagemaker\")\n",
    "\n",
    "# list all model packages and select the latest one\n",
    "model_packages = []\n",
    "\n",
    "for p in sm.get_paginator('list_model_packages').paginate(\n",
    "        ModelPackageGroupName=config['register_model_step']['model_group'],\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "    ):\n",
    "    model_packages.extend(p[\"ModelPackageSummaryList\"])\n",
    "\n",
    "if len(model_packages) == 0:\n",
    "    raise Exception(f\"No model package is found for {config['register_model_step']['model_group']} model package group\")\n",
    "\n",
    "## print the latest model, approve it\n",
    "latest_model_package_arn = model_packages[0][\"ModelPackageArn\"]\n",
    "logger.info(f\"for model_group={config['register_model_step']['model_group']}, latest_model_package_arn={latest_model_package_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following statement sets the ModelApprovalStatus for the model package to Approved. The model package state change will launch the EventBridge rule and the rule will launch the CodePipeline CI/CD pipeline with model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## updating the latest model package to approved status to use it for batch inference\n",
    "model_package_update_response = sm.update_model_package(\n",
    "    ModelPackageArn=latest_model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Batch Transform Pipeline: Prepare Batch Data & Perform Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first step is to get the latest batch data from presto and use that for batch transform step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the sklearn_processor in a SageMaker Pipelines ProcessingStep\n",
    "# Configure the ProcessingStep\n",
    "batch_data_prep = ProcessingStep(\n",
    "    name=config['data_processing_step']['step_name'],\n",
    "    processor=sklearn_processor,\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"batch\",\n",
    "            source=\"/opt/ml/processing/batch\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"batch\",\n",
    "                ], \n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    code = config['scripts']['batch_transform_get_data'],\n",
    "    job_arguments=[\n",
    "        ## these job parameters are required in the process of getting batch data from presto\n",
    "        ## and then send it to s3 for the process of batch inference\n",
    "        \"--host\", host_parameter, ## represents the host parameter for the batch data\n",
    "        \"--port\", port_parameter, ## represents the port for the EC2\n",
    "        \"--user\", user_parameter, ## represents the username for the presto\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Transform Configuration begins below:\n",
    "---\n",
    "\n",
    "1. Create the model with the model image uri, refer to the 'inference.py' script that grabs information on features to use while making predictions.\n",
    "\n",
    "2. Create the model which automatically triggers the training and the preprocess data step\n",
    "\n",
    "3. Run the transformer step on the created model and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 19:54:27,506] p17664 {1380157791.py:3} INFO - list_model_packages_response={'ModelPackageSummaryList': [{'ModelPackageGroupName': 'mlops-presto', 'ModelPackageVersion': 3, 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:015469603702:model-package/mlops-presto/3', 'CreationTime': datetime.datetime(2024, 2, 23, 19, 28, 38, 551000, tzinfo=tzlocal()), 'ModelPackageStatus': 'Completed', 'ModelApprovalStatus': 'Approved'}, {'ModelPackageGroupName': 'mlops-presto', 'ModelPackageVersion': 2, 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:015469603702:model-package/mlops-presto/2', 'CreationTime': datetime.datetime(2024, 2, 23, 19, 11, 42, 189000, tzinfo=tzlocal()), 'ModelPackageStatus': 'Completed', 'ModelApprovalStatus': 'PendingManualApproval'}, {'ModelPackageGroupName': 'mlops-presto', 'ModelPackageVersion': 1, 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:015469603702:model-package/mlops-presto/1', 'CreationTime': datetime.datetime(2024, 2, 23, 19, 11, 18, 479000, tzinfo=tzlocal()), 'ModelPackageStatus': 'Completed', 'ModelApprovalStatus': 'PendingManualApproval'}], 'ResponseMetadata': {'RequestId': '86cac0d5-cfaa-4488-b4a8-fae0f4239f85', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '86cac0d5-cfaa-4488-b4a8-fae0f4239f85', 'content-type': 'application/x-amz-json-1.1', 'content-length': '814', 'date': 'Fri, 23 Feb 2024 14:24:26 GMT'}, 'RetryAttempts': 0}}\n",
      "[2024-02-23 19:54:27,508] p17664 {1380157791.py:8} INFO - latest_model_version_arn=arn:aws:sagemaker:us-east-1:015469603702:model-package/mlops-presto/3\n"
     ]
    }
   ],
   "source": [
    "client = boto3.client(\"sagemaker\")\n",
    "list_model_packages_response = client.list_model_packages(ModelPackageGroupName=config['register_model_step']['model_group'])\n",
    "logger.info(f\"list_model_packages_response={list_model_packages_response}\")\n",
    "\n",
    "latest_model_version_arn = list_model_packages_response[\"ModelPackageSummaryList\"][0][\n",
    "    \"ModelPackageArn\"\n",
    "]\n",
    "logger.info(f\"latest_model_version_arn={latest_model_version_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 19:54:27,825] p17664 {226519901.py:5} INFO - The latest approved model package is --> {'ModelPackageGroupName': 'mlops-presto', 'ModelPackageVersion': 3, 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:015469603702:model-package/mlops-presto/3', 'CreationTime': datetime.datetime(2024, 2, 23, 19, 28, 38, 551000, tzinfo=tzlocal()), 'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3', 'ImageDigest': 'sha256:26e6faf825e29bb9fd048d3af6dc1c4e4fb1a172caa49bf7f68112324447f850', 'ModelDataUrl': 's3://sagemaker-us-east-1-015469603702/7dtbiu1emnry-Train-An-2I3X0W7DVE-001-1427a8db/output/model.tar.gz'}], 'SupportedTransformInstanceTypes': ['ml.m5.xlarge'], 'SupportedRealtimeInferenceInstanceTypes': ['ml.t2.medium', 'ml.m5.xlarge', 'ml.m5.large'], 'SupportedContentTypes': ['text/csv'], 'SupportedResponseMIMETypes': ['text/csv']}, 'ModelPackageStatus': 'Completed', 'ModelPackageStatusDetails': {'ValidationStatuses': [], 'ImageScanStatuses': []}, 'CertifyForMarketplace': False, 'ModelApprovalStatus': 'Approved', 'CreatedBy': {'IamIdentity': {'Arn': 'arn:aws:sts::015469603702:assumed-role/SageMakerRepoRole/sagemaker-pipeline-7dtbiu1emnry-Register-Model-Regis', 'PrincipalId': 'AROAQHGQPNN3EP6M2LKJQ:sagemaker-pipeline-7dtbiu1emnry-Register-Model-Regis'}}, 'MetadataProperties': {'GeneratedBy': 'arn:aws:sagemaker:us-east-1:015469603702:pipeline/mlops-pipeline-presto/execution/7dtbiu1emnry'}, 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json', 'S3Uri': 's3://sagemaker-us-east-1-015469603702/mlops-pipeline-model/evaluation/yyyy=2024/mm=2/dd=23/hh=13/mm=44/mlops-pipeline-model/7dtbiu1emnry/evaluation/evaluation.json'}}, 'Bias': {}, 'Explainability': {}}, 'LastModifiedTime': datetime.datetime(2024, 2, 23, 19, 54, 25, 114000, tzinfo=tzlocal()), 'LastModifiedBy': {'IamIdentity': {'Arn': 'arn:aws:iam::015469603702:user/iamadmin', 'PrincipalId': 'AIDAQHGQPNN3KE3RO7P6M'}}, 'SkipModelValidation': 'None', 'ResponseMetadata': {'RequestId': '5471eb03-a8f9-47e8-989c-1bbe27977afb', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '5471eb03-a8f9-47e8-989c-1bbe27977afb', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1768', 'date': 'Fri, 23 Feb 2024 14:24:27 GMT'}, 'RetryAttempts': 0}}\n",
      "[2024-02-23 19:54:27,826] p17664 {226519901.py:7} INFO - The model data for the latest approved model arn arn:aws:sagemaker:us-east-1:015469603702:model-package/mlops-presto/3 is stored in s3://sagemaker-us-east-1-015469603702/7dtbiu1emnry-Train-An-2I3X0W7DVE-001-1427a8db/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    latest_approved_model_package = client.describe_model_package(ModelPackageName=latest_model_version_arn)\n",
    "\n",
    "    if latest_approved_model_package['ModelApprovalStatus'] == \"Approved\":\n",
    "        logger.info(f\"The latest approved model package is --> {latest_approved_model_package}\")\n",
    "        model_data_url = latest_approved_model_package['InferenceSpecification']['Containers'][0]['ModelDataUrl']\n",
    "        logger.info(f\"The model data for the latest approved model arn {latest_model_version_arn} is stored in {model_data_url}\")\n",
    "    else:\n",
    "        # If the model approval status is not PendingApproval, throw an error exception\n",
    "        error_message = f\"ModelApprovalStatus is not PendingApproval. Current status: {latest_approved_model_package['ModelApprovalStatus']}\"\n",
    "        logger.error(error_message)\n",
    "        raise ValueError(error_message)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred while tracking the approved model: {str(e)}\")\n",
    "    raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create the model image based on the model data and refer to the inference script as an entry point for \n",
    "## batch inference\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    entry_point=config['scripts']['batch_inference'],\n",
    "    model_data=model_data_url,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model image from the approved model for batch inference in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aroraai\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sagemaker\\workflow\\pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "step_create_model = ModelStep(\n",
    "    name=config['register_model_step']['model_name'],\n",
    "    step_args=model.create(instance_type=config['transform_step']['instance_type']),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Transform Step to Perform Batch Transformation\n",
    "\n",
    "Now that a model instance is defined, create a Transformer instance with the appropriate model type, compute instance type, and desired output S3 URI.\n",
    "\n",
    "Specifically, pass in the ModelName from the CreateModelStep, step_create_model properties. The CreateModelStep properties attribute matches the object model of the DescribeModel response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Capture the current time for recording the start and end time for the batch transform step\n",
    "et = datetime.utcnow()\n",
    "st = et - timedelta(hours=config['transform_step']['num_hours_to_go_back'])\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=config['transform_step']['instance_type'],\n",
    "    instance_count=config['transform_step']['instance_count'],\n",
    "    strategy=\"MultiRecord\",\n",
    "    accept=\"text/csv\",\n",
    "    assemble_with=\"Line\",\n",
    "    output_path=f\"s3://{bucket}\",\n",
    "    tags = config['transform_step']['tags'], \n",
    "    env={\n",
    "        'START_TIME_UTC': st.strftime('%Y-%m-%d %H:%M:%S'), \n",
    "        'END_TIME_UTC': et.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    }\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass in the transformer instance and the TransformInput with the batch_data pipeline parameter defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "# Assuming batch_prediction_data is the S3 path where your input data is stored\n",
    "transform_input = TransformInput(\n",
    "    data=batch_data_prep.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"batch\" ## this refers to the batch data that is configured within s3 after the batch preprocessing step\n",
    "            ].S3Output.S3Uri,\n",
    "    \n",
    "    content_type=\"text/csv\", \n",
    "    split_type=\"Line\")\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=config['transform_step']['step_name'], transformer=transformer, inputs=transform_input, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = config['pipeline']['transform_pipeline_name']\n",
    "\n",
    "batch_transform_pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=\n",
    "    [processing_instance_type,\n",
    "    host_parameter,\n",
    "    port_parameter,\n",
    "    user_parameter,\n",
    "    target_parameter, \n",
    "    feature_parameter,],\n",
    "    \n",
    "    steps=[\n",
    "        batch_data_prep,\n",
    "        step_create_model, \n",
    "        step_transform,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 19:54:46,430] p17664 {utilities.py:465} WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-02-23 19:54:46,431] p17664 {utilities.py:465} WARNING - Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-02-23 19:54:46,432] p17664 {utilities.py:465} WARNING - Popping out 'TransformJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-02-23 19:54:49,184] p17664 {utilities.py:465} WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-02-23 19:54:49,186] p17664 {utilities.py:465} WARNING - Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-02-23 19:54:49,189] p17664 {utilities.py:465} WARNING - Popping out 'TransformJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:015469603702:pipeline/mlops-batch-inference',\n",
       " 'ResponseMetadata': {'RequestId': '0a46d64c-8a00-4ee4-a5e5-b12a776fd0f2',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0a46d64c-8a00-4ee4-a5e5-b12a776fd0f2',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '89',\n",
       "   'date': 'Fri, 23 Feb 2024 14:24:50 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_transform_pipeline.upsert(role_arn=role, tags = config['pipeline']['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = batch_transform_pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:015469603702:pipeline/mlops-batch-inference',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:015469603702:pipeline/mlops-batch-inference/execution/p7fq8w4xbveu',\n",
       " 'PipelineExecutionDisplayName': 'execution-1708698292901',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2024, 2, 23, 19, 54, 52, 854000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 2, 23, 19, 54, 52, 854000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {},\n",
       " 'LastModifiedBy': {},\n",
       " 'ResponseMetadata': {'RequestId': 'efd7f4bf-5843-48b7-b216-e378906e977a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'efd7f4bf-5843-48b7-b216-e378906e977a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '407',\n",
       "   'date': 'Fri, 23 Feb 2024 14:24:52 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-23 20:05:09,019] p17664 {2209960028.py:4} INFO - pipeline=mlops-batch-inference took -174150.27 seconds to run\n"
     ]
    }
   ],
   "source": [
    "st = time.perf_counter()\n",
    "execution.wait()\n",
    "et = time.perf_counter() - st\n",
    "logger.info(f\"pipeline={batch_transform_pipeline.name} took {et-st:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprint_pipeline_execution_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_transform_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aroraai\\repos\\twilio\\mlops-pipeline-prestodb\\utils.py:19\u001b[0m, in \u001b[0;36mprint_pipeline_execution_summary\u001b[1;34m(steps, name)\u001b[0m\n\u001b[0;32m     17\u001b[0m failed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     18\u001b[0m steps_that_had_to_retried \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 19\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline steps=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdumps(steps,\u001b[38;5;250m \u001b[39mindent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;250m \u001b[39mdefault\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStepStatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSucceeded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "print_pipeline_execution_summary(execution.list_steps(), batch_transform_pipeline.name)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
